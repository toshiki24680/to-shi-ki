#!/usr/bin/env python3
"""
å°å…«çˆ¬è™«ç®¡ç†ç³»ç»Ÿ v2.5 è‡ªåŠ¨åŒ–å¢å¼ºç‰ˆ - å®Œæ•´åŠŸèƒ½æ¼”ç¤º
å±•ç¤º45ç§’è‡ªåŠ¨çˆ¬è™«ã€å¤šè´¦å·ç®¡ç†ã€æ•°æ®ç´¯è®¡ã€å…³é”®è¯ç»Ÿè®¡ç­‰åŠŸèƒ½
"""

import requests
import json
import time
from datetime import datetime

# APIåŸºç¡€URL
API_BASE = "https://ffaa6b35-d505-4ab9-9968-ab9ba881d29f.preview.emergentagent.com/api"

def print_header():
    """æ‰“å°å¤´éƒ¨ä¿¡æ¯"""
    print("ğŸš€ å°å…«çˆ¬è™«ç®¡ç†ç³»ç»Ÿ v2.5 - è‡ªåŠ¨åŒ–å¢å¼ºç‰ˆ")
    print("="*80)
    print(f"ğŸ¯ ç›®æ ‡ç½‘ç«™: http://xiao8.lodsve.com:6007/x8login")
    print(f"ğŸŒ å‰ç«¯ç•Œé¢: https://ffaa6b35-d505-4ab9-9968-ab9ba881d29f.preview.emergentagent.com")
    print(f"ğŸ”— åç«¯API: {API_BASE}")
    print(f"â° æ¼”ç¤ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("="*80)

def demo_version_upgrade():
    """æ¼”ç¤ºç‰ˆæœ¬å‡çº§ä¿¡æ¯"""
    print("\nğŸ¯ ç‰ˆæœ¬å‡çº§ä¿¡æ¯ v2.1 â†’ v2.5")
    print("-" * 50)
    
    try:
        response = requests.get(f"{API_BASE}/version")
        if response.status_code == 200:
            version_info = response.json()
            
            print(f"âœ… å½“å‰ç‰ˆæœ¬: v{version_info['version']}")
            print(f"ğŸ“… æ›´æ–°æ—¥æœŸ: {version_info['update_date']}")
            
            print(f"\nğŸ”§ æ–°å¢åŠŸèƒ½ç‰¹æ€§:")
            for feature in version_info['features']:
                print(f"    â€¢ {feature}")
            
            print(f"\nğŸ“‹ ç‰ˆæœ¬æ›´æ–°æ—¥å¿—:")
            for change in version_info['changelog']:
                print(f"    {change}")
            
            return True
    except Exception as e:
        print(f"âŒ ç‰ˆæœ¬ä¿¡æ¯è·å–å¤±è´¥: {e}")
        return False

def demo_auto_crawler():
    """æ¼”ç¤º45ç§’è‡ªåŠ¨çˆ¬è™«åŠŸèƒ½"""
    print("\nğŸ¤– 45ç§’è‡ªåŠ¨çˆ¬è™«åŠŸèƒ½æ¼”ç¤º")
    print("-" * 50)
    
    try:
        # å¯åŠ¨è‡ªåŠ¨çˆ¬è™«
        print("1. å¯åŠ¨45ç§’è‡ªåŠ¨çˆ¬è™«...")
        response = requests.post(f"{API_BASE}/crawler/auto/start")
        if response.status_code == 200:
            data = response.json()
            print(f"   âœ… {data['message']}")
            print(f"   â° çˆ¬å–é—´éš”: {data['interval']}")
        
        time.sleep(2)
        
        # æ£€æŸ¥è‡ªåŠ¨çˆ¬è™«çŠ¶æ€
        print("\n2. æ£€æŸ¥è‡ªåŠ¨çˆ¬è™«çŠ¶æ€...")
        response = requests.get(f"{API_BASE}/crawler/auto/status")
        if response.status_code == 200:
            status = response.json()
            print(f"   ğŸ”„ è¿è¡ŒçŠ¶æ€: {'è¿è¡Œä¸­' if status['running'] else 'å·²åœæ­¢'}")
            print(f"   â±ï¸  çˆ¬å–é—´éš”: {status['interval']} ç§’")
            print(f"   ğŸ‘¥ æ€»è´¦å·æ•°: {status['total_accounts']}")
            print(f"   ğŸŸ¢ æ´»è·ƒè´¦å·: {status['active_accounts']}")
            print(f"   ğŸ“Š å†å²è®°å½•: {status['crawl_history_count']} æ¡")
        
        print("\n3. ç­‰å¾…ä¸€ä¸ªå‘¨æœŸè§‚å¯Ÿè‡ªåŠ¨è¿è¡Œ...")
        print("   ğŸ• ç­‰å¾…ä¸­... (å¯åœ¨å‰ç«¯ç•Œé¢è§‚å¯Ÿå®æ—¶çŠ¶æ€)")
        time.sleep(10)
        
        # å†æ¬¡æ£€æŸ¥çŠ¶æ€å˜åŒ–
        response = requests.get(f"{API_BASE}/crawler/auto/status")
        if response.status_code == 200:
            status = response.json()
            print(f"   âœ… è‡ªåŠ¨çˆ¬è™«ä»åœ¨è¿è¡Œ: {status['running']}")
        
        return True
    except Exception as e:
        print(f"âŒ è‡ªåŠ¨çˆ¬è™«åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def demo_account_management():
    """æ¼”ç¤ºå¤šè´¦å·ç®¡ç†åŠŸèƒ½"""
    print("\nğŸ‘¥ å¤šè´¦å·ç®¡ç†åŠŸèƒ½æ¼”ç¤º")
    print("-" * 50)
    
    try:
        # è·å–ç°æœ‰è´¦å·
        print("1. è·å–ç°æœ‰è´¦å·åˆ—è¡¨...")
        response = requests.get(f"{API_BASE}/accounts")
        if response.status_code == 200:
            accounts = response.json()
            print(f"   ğŸ“Š å½“å‰è´¦å·æ•°: {len(accounts)}")
            for acc in accounts[:3]:  # æ˜¾ç¤ºå‰3ä¸ª
                print(f"     â€¢ {acc['username']} - çŠ¶æ€: {acc['status']} - è‡ªåŠ¨å¯ç”¨: {acc.get('is_auto_enabled', True)}")
        
        # æ·»åŠ æ–°è´¦å·
        print("\n2. æ·»åŠ æ–°æµ‹è¯•è´¦å·...")
        new_account = {
            "username": f"TEST_{int(time.time())}",
            "password": "test123",
            "preferred_guild": "æµ‹è¯•é—¨æ´¾"
        }
        
        response = requests.post(f"{API_BASE}/accounts", json=new_account)
        if response.status_code == 200:
            created_account = response.json()
            print(f"   âœ… è´¦å·åˆ›å»ºæˆåŠŸ: {created_account['username']}")
            account_id = created_account['id']
            
            # æ›´æ–°è´¦å·ä¿¡æ¯
            print("\n3. æ›´æ–°è´¦å·è®¾ç½®...")
            update_data = {"is_auto_enabled": False, "status": "paused"}
            response = requests.put(f"{API_BASE}/accounts/{account_id}", json=update_data)
            if response.status_code == 200:
                print("   âœ… è´¦å·æ›´æ–°æˆåŠŸ")
            
            # æ‰¹é‡æ“ä½œæ¼”ç¤º
            print("\n4. æ‰¹é‡æ“ä½œæ¼”ç¤º...")
            batch_data = {
                "account_ids": [account_id],
                "operation": "stop"
            }
            response = requests.post(f"{API_BASE}/accounts/batch", json=batch_data)
            if response.status_code == 200:
                print("   âœ… æ‰¹é‡åœæ­¢æ“ä½œæˆåŠŸ")
            
            # åˆ é™¤æµ‹è¯•è´¦å·
            print("\n5. åˆ é™¤æµ‹è¯•è´¦å·...")
            response = requests.delete(f"{API_BASE}/accounts/{account_id}")
            if response.status_code == 200:
                print("   âœ… æµ‹è¯•è´¦å·åˆ é™¤æˆåŠŸ")
        
        return True
    except Exception as e:
        print(f"âŒ è´¦å·ç®¡ç†åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def demo_data_features():
    """æ¼”ç¤ºæ•°æ®ç´¯è®¡å’Œç­›é€‰åŠŸèƒ½"""
    print("\nğŸ“Š æ•°æ®ç´¯è®¡å’Œç­›é€‰åŠŸèƒ½æ¼”ç¤º")
    print("-" * 50)
    
    try:
        # ç”Ÿæˆæµ‹è¯•æ•°æ®
        print("1. ç”Ÿæˆå¸ˆé—¨æµ‹è¯•æ•°æ®...")
        response = requests.post(f"{API_BASE}/crawler/mock-data")
        if response.status_code == 200:
            data = response.json()
            print(f"   âœ… {data['message']}")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        print("\n2. è·å–æ•°æ®ç»Ÿè®¡åˆ†æ...")
        response = requests.get(f"{API_BASE}/crawler/stats")
        if response.status_code == 200:
            stats = response.json()
            
            basic = stats.get('basic_stats', {})
            accumulation = stats.get('accumulation_stats', {})
            
            print("   ğŸ“ˆ åŸºç¡€ç»Ÿè®¡:")
            print(f"     â€¢ æ€»è®°å½•æ•°: {basic.get('total_records', 0)}")
            print(f"     â€¢ ç‹¬ç«‹è´¦å·: {basic.get('unique_accounts', 0)}")
            print(f"     â€¢ ä¸åŒé—¨æ´¾: {basic.get('unique_guilds', 0)}")
            print(f"     â€¢ å¹³å‡ç­‰çº§: {basic.get('avg_level', 0):.1f}")
            
            print("   ğŸ”„ ç´¯è®¡æ•°æ®ç»Ÿè®¡:")
            print(f"     â€¢ æ€»ç´¯è®¡æ¬¡æ•°: {accumulation.get('total_accumulated_count', 0)}")
            print(f"     â€¢ æ€»é‡ç½®å‘¨æœŸ: {accumulation.get('total_cycles', 0)}")
            print(f"     â€¢ å¹³å‡ç´¯è®¡/è®°å½•: {accumulation.get('avg_accumulated_per_record', 0):.2f}")
        
        # æ•°æ®ç­›é€‰æ¼”ç¤º
        print("\n3. æ•°æ®ç­›é€‰åŠŸèƒ½æ¼”ç¤º...")
        filter_data = {
            "guild": "æ™®é™€å±±",
            "min_level": 80,
            "max_level": 120
        }
        
        response = requests.post(f"{API_BASE}/crawler/data/filter", json=filter_data)
        if response.status_code == 200:
            result = response.json()
            print(f"   ğŸ” ç­›é€‰ç»“æœ: ä» {result.get('total_count', 0)} æ¡è®°å½•ä¸­ç­›é€‰å‡º {result.get('filtered_count', 0)} æ¡")
            print(f"   ğŸ“‹ ç­›é€‰æ¡ä»¶: é—¨æ´¾=æ™®é™€å±±, ç­‰çº§=80-120")
        
        return True
    except Exception as e:
        print(f"âŒ æ•°æ®åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def demo_keyword_monitoring():
    """æ¼”ç¤ºå…³é”®è¯ç»Ÿè®¡åŠŸèƒ½"""
    print("\nğŸš¨ å…³é”®è¯ç›‘æ§åŠŸèƒ½æ¼”ç¤º")
    print("-" * 50)
    
    try:
        # è·å–å…³é”®è¯ç»Ÿè®¡
        print("1. è·å–å…³é”®è¯ç›‘æ§ç»Ÿè®¡...")
        response = requests.get(f"{API_BASE}/crawler/keywords")
        if response.status_code == 200:
            stats = response.json()
            
            print(f"   ğŸ“Š æ€»æ£€æµ‹æ¬¡æ•°: {stats.get('total_keywords_detected', 0)}")
            print(f"   ğŸ¯ è§¦å‘å…³é”®è¯æ•°: {stats.get('unique_keywords', 0)}")
            print(f"   ğŸ‘€ ç›‘æ§å…³é”®è¯: {len(stats.get('monitored_keywords', []))}")
            
            print("   ğŸ” ç›‘æ§å…³é”®è¯åˆ—è¡¨:")
            for keyword in stats.get('monitored_keywords', [])[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                count = stats.get('keyword_stats', {}).get(keyword, 0)
                print(f"     â€¢ {keyword}: {count} æ¬¡")
        
        # é‡ç½®å…³é”®è¯ç»Ÿè®¡
        print("\n2. é‡ç½®å…³é”®è¯ç»Ÿè®¡...")
        response = requests.post(f"{API_BASE}/crawler/keywords/reset")
        if response.status_code == 200:
            print("   âœ… å…³é”®è¯ç»Ÿè®¡å·²é‡ç½®")
        
        return True
    except Exception as e:
        print(f"âŒ å…³é”®è¯ç›‘æ§åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def demo_crawl_history():
    """æ¼”ç¤ºçˆ¬å–å†å²åŠŸèƒ½"""
    print("\nğŸ“ˆ çˆ¬å–å†å²åŠŸèƒ½æ¼”ç¤º")
    print("-" * 50)
    
    try:
        response = requests.get(f"{API_BASE}/crawler/history")
        if response.status_code == 200:
            history = response.json()
            
            print(f"   ğŸ“Š æ€»çˆ¬å–æ¬¡æ•°: {history.get('total_crawls', 0)}")
            print(f"   âœ… æˆåŠŸç‡: {(history.get('success_rate', 0) * 100):.1f}%")
            
            recent_history = history.get('history', [])[-5:]  # æœ€è¿‘5æ¡
            if recent_history:
                print("   ğŸ“‹ æœ€è¿‘çˆ¬å–è®°å½•:")
                for entry in recent_history:
                    status = "æˆåŠŸ" if entry.get('success') else "å¤±è´¥"
                    print(f"     â€¢ {entry.get('account')} - {status} - {entry.get('data_count', 0)} æ¡æ•°æ® - {entry.get('timestamp', '')[:19]}")
        
        return True
    except Exception as e:
        print(f"âŒ çˆ¬å–å†å²åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def demo_export_function():
    """æ¼”ç¤ºå¢å¼ºçš„å¯¼å‡ºåŠŸèƒ½"""
    print("\nğŸ“ å¢å¼ºCSVå¯¼å‡ºåŠŸèƒ½æ¼”ç¤º")
    print("-" * 50)
    
    try:
        print("1. æµ‹è¯•å¢å¼ºCSVå¯¼å‡º...")
        response = requests.get(f"{API_BASE}/crawler/data/export")
        if response.status_code == 200:
            print(f"   âœ… CSVå¯¼å‡ºæˆåŠŸ")
            print(f"   ğŸ“Š æ–‡ä»¶å¤§å°: {len(response.content)} å­—èŠ‚")
            print(f"   ğŸ“‹ å†…å®¹ç±»å‹: {response.headers.get('Content-Type', 'æœªçŸ¥')}")
            
            # å°è¯•è§£æCSVå†…å®¹é¢„è§ˆ
            try:
                content = response.content.decode('utf-8-sig')
                lines = content.split('\n')[:3]
                print("   ğŸ“„ å†…å®¹é¢„è§ˆ:")
                for line in lines:
                    if line.strip():
                        print(f"     {line}")
            except Exception:
                print("   ğŸ“„ å¯¼å‡ºæ–‡ä»¶ä¸ºäºŒè¿›åˆ¶æ ¼å¼")
        
        return True
    except Exception as e:
        print(f"âŒ å¯¼å‡ºåŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False

def demo_frontend_features():
    """æ¼”ç¤ºå‰ç«¯ç•Œé¢ç‰¹æ€§"""
    print("\nğŸ¨ å‰ç«¯ç•Œé¢ç‰¹æ€§å±•ç¤º")
    print("-" * 50)
    
    frontend_url = "https://ffaa6b35-d505-4ab9-9968-ab9ba881d29f.preview.emergentagent.com"
    
    print("âœ¨ å…¨æ–°5æ ‡ç­¾é¡µç•Œé¢è®¾è®¡:")
    print(f"   ğŸ  æ•°æ®é¢æ¿ - å®æ—¶æ˜¾ç¤ºçˆ¬è™«æ•°æ®å’ŒçŠ¶æ€")
    print(f"   ğŸ” æ•°æ®ç­›é€‰ - å¤šç»´åº¦ç­›é€‰å’Œæœç´¢åŠŸèƒ½")
    print(f"   ğŸ‘¥ è´¦å·ç®¡ç† - å®Œæ•´çš„è´¦å·CRUDæ“ä½œå’Œæ‰¹é‡æ§åˆ¶")
    print(f"   ğŸ“Š ç»Ÿè®¡åˆ†æ - æ•°æ®æ‘˜è¦å’Œæ€§èƒ½åˆ†æ")
    print(f"   ğŸš¨ å…³é”®è¯ç»Ÿè®¡ - å¼‚å¸¸å…³é”®è¯ç›‘æ§å’Œç»Ÿè®¡")
    
    print(f"\nğŸŒ å‰ç«¯è®¿é—®åœ°å€: {frontend_url}")
    print("ğŸ¯ ç•Œé¢ç‰¹ç‚¹:")
    print("   â€¢ ç°ä»£åŒ–æ¸å˜è‰²è®¾è®¡")
    print("   â€¢ å“åº”å¼å¸ƒå±€ï¼Œé€‚é…å„ç§å±å¹•")
    print("   â€¢ å®æ—¶æ•°æ®æ›´æ–°ï¼Œ30ç§’è‡ªåŠ¨åˆ·æ–°")
    print("   â€¢ ç›´è§‚çš„çŠ¶æ€æŒ‡ç¤ºå™¨å’Œè¿›åº¦æ¡")
    print("   â€¢ äº¤äº’å¼æ•°æ®è¡¨æ ¼å’Œç­›é€‰å™¨")

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print_header()
    
    # æ¼”ç¤ºå„ä¸ªåŠŸèƒ½æ¨¡å—
    results = {}
    
    print("\nğŸ¬ å¼€å§‹åŠŸèƒ½æ¼”ç¤º...")
    
    results['version'] = demo_version_upgrade()
    time.sleep(1)
    
    results['auto_crawler'] = demo_auto_crawler()
    time.sleep(1)
    
    results['account_mgmt'] = demo_account_management()
    time.sleep(1)
    
    results['data_features'] = demo_data_features()
    time.sleep(1)
    
    results['keyword_monitoring'] = demo_keyword_monitoring()
    time.sleep(1)
    
    results['crawl_history'] = demo_crawl_history()
    time.sleep(1)
    
    results['export'] = demo_export_function()
    time.sleep(1)
    
    demo_frontend_features()
    
    # æ€»ç»“
    print("\nğŸ‰ v2.5 è‡ªåŠ¨åŒ–å¢å¼ºç‰ˆæ¼”ç¤ºå®Œæˆï¼")
    print("="*80)
    
    # åŠŸèƒ½æµ‹è¯•ç»“æœ
    successful_tests = sum(1 for success in results.values() if success)
    total_tests = len(results)
    
    print(f"ğŸ“Š åŠŸèƒ½æµ‹è¯•ç»“æœ: {successful_tests}/{total_tests} é€šè¿‡")
    print("âœ¨ æ–°åŠŸèƒ½äº®ç‚¹:")
    print("   ğŸ¤– 45ç§’è‡ªåŠ¨çˆ¬è™« - æŒç»­ç›‘æ§å¸ˆé—¨çŠ¶æ€")
    print("   ğŸ‘¥ å®Œæ•´è´¦å·ç®¡ç† - æ·»åŠ /åˆ é™¤/æ‰¹é‡æ“ä½œ")
    print("   ğŸ”„ æ•°æ®ç´¯è®¡é€»è¾‘ - æ™ºèƒ½æ£€æµ‹é‡ç½®å‘¨æœŸ")
    print("   ğŸš¨ å…³é”®è¯ç›‘æ§ - å®æ—¶æ£€æµ‹å¼‚å¸¸çŠ¶æ€")
    print("   ğŸ“Š æ•°æ®ç­›é€‰åˆ†æ - å¤šç»´åº¦æ•°æ®æŒ–æ˜")
    print("   ğŸ“ å¢å¼ºCSVå¯¼å‡º - åŒ…å«ç´¯è®¡æ•°æ®ç»Ÿè®¡")
    print("   ğŸ¨ å…¨æ–°UIç•Œé¢ - 5æ ‡ç­¾é¡µä¸“ä¸šè®¾è®¡")
    
    print(f"\nğŸŒ ç«‹å³ä½“éªŒ:")
    print("   å‰ç«¯: https://ffaa6b35-d505-4ab9-9968-ab9ba881d29f.preview.emergentagent.com")
    print("   API:  https://ffaa6b35-d505-4ab9-9968-ab9ba881d29f.preview.emergentagent.com/api")
    
    print(f"\nğŸ¯ å»ºè®®æ“ä½œ:")
    print("   1. è®¿é—®å‰ç«¯ç•Œé¢ä½“éªŒ5ä¸ªåŠŸèƒ½æ ‡ç­¾é¡µ")
    print("   2. å¯åŠ¨45ç§’è‡ªåŠ¨çˆ¬è™«è§‚å¯Ÿå®æ—¶æ•ˆæœ")
    print("   3. åœ¨è´¦å·ç®¡ç†é¡µé¢æ·»åŠ /åˆ é™¤è´¦å·")
    print("   4. ä½¿ç”¨æ•°æ®ç­›é€‰åŠŸèƒ½è¿›è¡Œå¤šç»´åº¦åˆ†æ")
    print("   5. æŸ¥çœ‹ç»Ÿè®¡åˆ†æäº†è§£ç³»ç»Ÿè¿è¡ŒçŠ¶å†µ")

if __name__ == "__main__":
    main()